{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelado Predictivo de Tiempos de Inactividad\n",
    "\n",
    "Este notebook desarrolla modelos predictivos para anticipar tiempos de inactividad en la línea de producción.\n",
    "\n",
    "## Objetivos\n",
    "1. Preparar datos para modelado predictivo\n",
    "2. Desarrollar modelos de predicción\n",
    "3. Evaluar y comparar modelos\n",
    "4. Generar predicciones y recomendaciones\n",
    "\n",
    "## Requisitos\n",
    "- Python 3.8+\n",
    "- Paquetes listados en requirements.txt\n",
    "- Acceso a la base de datos de producción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.db_connection import create_connection, read_table\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# Configurar reproducibilidad\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cargar datos\n",
    "conn = create_connection()\n",
    "production_data = read_table(conn, 'manufacturing_line_productivity')\n",
    "downtime_data = read_table(conn, 'normalizeddowntime')\n",
    "factors_data = read_table(conn, 'downtime_factor')\n",
    "\n",
    "# Preparar características\n",
    "def prepare_features(prod_data, down_data, fact_data):\n",
    "    # Agregar tiempo de inactividad total por lote\n",
    "    batch_downtime = down_data.groupby('batch')['downtime_minutes'].sum().reset_index()\n",
    "    \n",
    "    # Unir con datos de producción\n",
    "    df = pd.merge(prod_data, batch_downtime, on='batch', how='left')\n",
    "    \n",
    "    # Convertir fecha a datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Extraer características temporales\n",
    "    df['weekday'] = df['date'].dt.dayofweek\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['hour'] = pd.to_datetime(df['Star_Time']).dt.hour\n",
    "    \n",
    "    # Codificar variables categóricas\n",
    "    df = pd.get_dummies(df, columns=['flavor', 'size', 'operator'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Preparar dataset\n",
    "model_data = prepare_features(production_data, downtime_data, factors_data)\n",
    "\n",
    "# Separar características y objetivo\n",
    "target = 'downtime_minutes'\n",
    "features = [col for col in model_data.columns if col not in [target, 'date', 'Star_Time', 'End_Time', 'batch']]\n",
    "\n",
    "X = model_data[features]\n",
    "y = model_data[target]\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar características\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Desarrollo del Modelo Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Entrenar modelo Random Forest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluar modelo\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Calcular métricas\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Métricas del Modelo:\")\n",
    "print(f\"RMSE: {rmse:.2f} minutos\")\n",
    "print(f\"MAE: {mae:.2f} minutos\")\n",
    "print(f\"R²: {r2:.3f}\")\n",
    "\n",
    "# Visualizar predicciones vs valores reales\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Tiempo de Inactividad Real (minutos)')\n",
    "plt.ylabel('Tiempo de Inactividad Predicho (minutos)')\n",
    "plt.title('Predicciones vs Valores Reales')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/predictions_vs_actual.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análisis de Importancia de Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calcular importancia de características\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': rf_model.feature_importances_\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "# Visualizar importancia de características\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=feature_importance.head(15), x='importance', y='feature')\n",
    "plt.title('Top 15 Características más Importantes')\n",
    "plt.xlabel('Importancia')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/feature_importance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predicciones para Nuevos Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def predict_downtime(model, scaler, new_data):\n",
    "    \"\"\"\n",
    "    Realiza predicciones para nuevos datos de producción.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo entrenado\n",
    "        scaler: Scaler ajustado\n",
    "        new_data: DataFrame con nuevos datos de producción\n",
    "    \n",
    "    Returns:\n",
    "        Predicciones de tiempo de inactividad\n",
    "    \"\"\"\n",
    "    # Preparar nuevos datos\n",
    "    prepared_data = prepare_features(new_data, pd.DataFrame(), pd.DataFrame())\n",
    "    \n",
    "    # Asegurar que tenemos todas las columnas necesarias\n",
    "    missing_cols = set(features) - set(prepared_data.columns)\n",
    "    for col in missing_cols:\n",
    "        prepared_data[col] = 0\n",
    "    \n",
    "    # Ordenar columnas como en el entrenamiento\n",
    "    prepared_data = prepared_data[features]\n",
    "    \n",
    "    # Escalar datos\n",
    "    scaled_data = scaler.transform(prepared_data)\n",
    "    \n",
    "    # Realizar predicción\n",
    "    predictions = model.predict(scaled_data)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Ejemplo de uso con los últimos datos disponibles\n",
    "recent_data = production_data.sort_values('date').tail(5)\n",
    "predictions = predict_downtime(rf_model, scaler, recent_data)\n",
    "\n",
    "print(\"\\nPredicciones para los últimos 5 lotes:\")\n",
    "for batch, pred in zip(recent_data['batch'], predictions):\n",
    "    print(f\"Lote {batch}: {pred:.2f} minutos de inactividad predichos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Validación Cruzada y Robustez del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Realizar validación cruzada\n",
    "cv_scores = cross_val_score(rf_model, X_train_scaled, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "cv_rmse = -cv_scores\n",
    "\n",
    "print(\"\\nResultados de Validación Cruzada (RMSE):\")\n",
    "print(f\"Media: {cv_rmse.mean():.2f} minutos\")\n",
    "print(f\"Desviación Estándar: {cv_rmse.std():.2f} minutos\")\n",
    "\n",
    "# Visualizar distribución de errores\n",
    "plt.figure(figsize=(10, 6))\n",
    "residuals = y_test - y_pred\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title('Distribución de Errores de Predicción')\n",
    "plt.xlabel('Error (minutos)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/prediction_errors.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusiones y Recomendaciones\n",
    "\n",
    "### Rendimiento del Modelo\n",
    "1. Precisión:\n",
    "   - RMSE: [Completar] minutos\n",
    "   - R²: [Completar]\n",
    "   - El modelo explica [X]% de la variabilidad en los tiempos de inactividad\n",
    "\n",
    "### Factores Principales\n",
    "1. Las características más influyentes son:\n",
    "   - [Completar con top 3 características]\n",
    "   - [Explicar implicaciones]\n",
    "\n",
    "### Recomendaciones Operativas\n",
    "1. Enfoque en Prevención:\n",
    "   - [Completar con recomendaciones basadas en características importantes]\n",
    "2. Monitoreo Continuo:\n",
    "   - [Completar con estrategia de seguimiento]\n",
    "3. Mejoras Sugeridas:\n",
    "   - [Completar con acciones específicas]\n",
    "\n",
    "## Próximos Pasos\n",
    "\n",
    "1. Implementación en Producción:\n",
    "   - Desarrollar API para predicciones en tiempo real\n",
    "   - Integrar con sistemas existentes\n",
    "\n",
    "2. Mejoras del Modelo:\n",
    "   - Incorporar variables adicionales\n",
    "   - Experimentar con otros algoritmos\n",
    "   - Actualización periódica con nuevos datos\n",
    "\n",
    "3. Validación Continua:\n",
    "   - Monitorear rendimiento del modelo\n",
    "   - Ajustar según retroalimentación\n",
    "   - Documentar casos de éxito y áreas de mejora"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
